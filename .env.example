# LLM Configuration
HUGGINGFACE_API_KEY=hf_your_token_here
LLM_PROVIDER=huggingface        # use "ollama" only if serving Qwen locally
LLM_MODEL=Qwen/Qwen2.5-7B-Instruct
OLLAMA_BASE_URL=http://localhost:11434

# MCP Configuration
MCP_MODE=real                   # or "sandbox" for demo mode

# Vector Store / RAG
VECTOR_STORE_PATH=vector_store/faiss_index
EMBEDDING_MODEL=BAAI/bge-large-en
RUNBOOKS_PATH=runbooks/

# Agent Configuration
MAX_PLAN_STEPS=10
RISK_THRESHOLD=0.7
REQUIRE_APPROVAL=true

# UI Configuration
GRADIO_PORT=7860
GRADIO_SHARE=false